{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhuriawachar1/DSOnMacARM/blob/main/podcast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this Demo, we will:\n",
        "\n",
        "1. Download ggml-whisper which is a really fast version of whisper written in C/C++\n",
        "2. Convert an audio file with any format to wav (the only format currently supported by ggml-whisper)\n",
        "3. Convert the transcription to csv and save for model training later"
      ],
      "metadata": {
        "id": "uLih1l-Xr4FD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e27e-ve03eyh"
      },
      "source": [
        "## Download an example video"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2tGjV1AqRs5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/1.mp3 \"https://www.dropbox.com/s/9llt4ptcqvr77md/1.mp3?dl=0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq7Y7o7Zs00o",
        "outputId": "cd54da58-b1ee-48b3-fcb6-a5401733b2bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-05 07:44:42--  https://www.dropbox.com/s/9llt4ptcqvr77md/1.mp3?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/9llt4ptcqvr77md/1.mp3 [following]\n",
            "--2023-08-05 07:44:42--  https://www.dropbox.com/s/raw/9llt4ptcqvr77md/1.mp3\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucd7a98ceb5bbb92a61a362a6371.dl.dropboxusercontent.com/cd/0/inline/CBPaxdWW0kHX7tZ9G5xDTfyTkdBENayjIlGs9IhhFT0bEidBVcOMNOSfCCxuXeQ1L2qWK2F8OcVFg1T7QVDgM-9u0G_96tv45mm3hWHolMtD0RydWsWkfN3XO6ad2_E5CgSWkuSeex5pKKf3JvcBH5D2/file# [following]\n",
            "--2023-08-05 07:44:42--  https://ucd7a98ceb5bbb92a61a362a6371.dl.dropboxusercontent.com/cd/0/inline/CBPaxdWW0kHX7tZ9G5xDTfyTkdBENayjIlGs9IhhFT0bEidBVcOMNOSfCCxuXeQ1L2qWK2F8OcVFg1T7QVDgM-9u0G_96tv45mm3hWHolMtD0RydWsWkfN3XO6ad2_E5CgSWkuSeex5pKKf3JvcBH5D2/file\n",
            "Resolving ucd7a98ceb5bbb92a61a362a6371.dl.dropboxusercontent.com (ucd7a98ceb5bbb92a61a362a6371.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucd7a98ceb5bbb92a61a362a6371.dl.dropboxusercontent.com (ucd7a98ceb5bbb92a61a362a6371.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6915017 (6.6M) [audio/mpeg]\n",
            "Saving to: ‘/content/1.mp3’\n",
            "\n",
            "/content/1.mp3      100%[===================>]   6.59M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-08-05 07:44:43 (90.6 MB/s) - ‘/content/1.mp3’ saved [6915017/6915017]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "F7n_NfZcuszO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b5771d-782a-4d5a-f2b3-50513720ef3b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import shutil\n",
        "for i in range(1,25):\n",
        "  str1=str(i)\n",
        "  s=\"/content/drive/MyDrive/\"+str1+\".mp3\"\n",
        "  d=\"/content/\"+str1+\".mp3\"\n",
        "  # Define the source and destination paths\n",
        "  source_path = s\n",
        "  destination_path = d\n",
        "\n",
        "  # Move the file\n",
        "  shutil.move(source_path, destination_path)'''\n"
      ],
      "metadata": {
        "id": "F9wjT-MOypbA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogcy9q2V3jjK"
      },
      "source": [
        "## Download ggml-whisper repo and compile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/whisper.cpp.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThvylUNhFoz8",
        "outputId": "6b912cad-c989-48a6-d869-f61b28f9a683"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'whisper.cpp'...\n",
            "remote: Enumerating objects: 4091, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 4091 (delta 29), reused 47 (delta 15), pack-reused 4015\u001b[K\n",
            "Receiving objects: 100% (4091/4091), 7.00 MiB | 10.68 MiB/s, done.\n",
            "Resolving deltas: 100% (2552/2552), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/whisper.cpp/models\n",
        "!bash download-ggml-model.sh base.en\n",
        "%cd ..\n",
        "!make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3JnpQojLD_",
        "outputId": "d97d2d35-3089-4e41-b073-56a58eb12be1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/whisper.cpp/models\n",
            "Downloading ggml model base.en from 'https://huggingface.co/ggerganov/whisper.cpp' ...\n",
            "ggml-base.en.bin    100%[===================>] 141.11M   204MB/s    in 0.7s    \n",
            "Done! Model 'base.en' saved in 'models/ggml-base.en.bin'\n",
            "You can now use it like this:\n",
            "\n",
            "  $ ./main -m models/ggml-base.en.bin -f samples/jfk.wav\n",
            "\n",
            "/content/whisper.cpp\n",
            "I whisper.cpp build info: \n",
            "I UNAME_S:  Linux\n",
            "I UNAME_P:  x86_64\n",
            "I UNAME_M:  x86_64\n",
            "I CFLAGS:   -I.              -O3 -DNDEBUG -std=c11   -fPIC -pthread -mavx2 -mfma -mf16c -mavx -msse3\n",
            "I CXXFLAGS: -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -pthread\n",
            "I LDFLAGS:  \n",
            "I CC:       cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:      g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "cc  -I.              -O3 -DNDEBUG -std=c11   -fPIC -pthread -mavx2 -mfma -mf16c -mavx -msse3   -c ggml.c -o ggml.o\n",
            "g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -pthread -c whisper.cpp -o whisper.o\n",
            "g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -pthread examples/main/main.cpp examples/common.cpp examples/common-ggml.cpp ggml.o whisper.o -o main \n",
            "./main -h\n",
            "\n",
            "usage: ./main [options] file0.wav file1.wav ...\n",
            "\n",
            "options:\n",
            "  -h,        --help              [default] show this help message and exit\n",
            "  -t N,      --threads N         [2      ] number of threads to use during computation\n",
            "  -p N,      --processors N      [1      ] number of processors to use during computation\n",
            "  -ot N,     --offset-t N        [0      ] time offset in milliseconds\n",
            "  -on N,     --offset-n N        [0      ] segment index offset\n",
            "  -d  N,     --duration N        [0      ] duration of audio to process in milliseconds\n",
            "  -mc N,     --max-context N     [-1     ] maximum number of text context tokens to store\n",
            "  -ml N,     --max-len N         [0      ] maximum segment length in characters\n",
            "  -sow,      --split-on-word     [false  ] split on word rather than on token\n",
            "  -bo N,     --best-of N         [2      ] number of best candidates to keep\n",
            "  -bs N,     --beam-size N       [-1     ] beam size for beam search\n",
            "  -wt N,     --word-thold N      [0.01   ] word timestamp probability threshold\n",
            "  -et N,     --entropy-thold N   [2.40   ] entropy threshold for decoder fail\n",
            "  -lpt N,    --logprob-thold N   [-1.00  ] log probability threshold for decoder fail\n",
            "  -su,       --speed-up          [false  ] speed up audio by x2 (reduced accuracy)\n",
            "  -tr,       --translate         [false  ] translate from source language to english\n",
            "  -di,       --diarize           [false  ] stereo audio diarization\n",
            "  -tdrz,     --tinydiarize       [false  ] enable tinydiarize (requires a tdrz model)\n",
            "  -nf,       --no-fallback       [false  ] do not use temperature fallback while decoding\n",
            "  -otxt,     --output-txt        [false  ] output result in a text file\n",
            "  -ovtt,     --output-vtt        [false  ] output result in a vtt file\n",
            "  -osrt,     --output-srt        [false  ] output result in a srt file\n",
            "  -olrc,     --output-lrc        [false  ] output result in a lrc file\n",
            "  -owts,     --output-words      [false  ] output script for generating karaoke video\n",
            "  -fp,       --font-path         [/System/Library/Fonts/Supplemental/Courier New Bold.ttf] path to a monospace font for karaoke video\n",
            "  -ocsv,     --output-csv        [false  ] output result in a CSV file\n",
            "  -oj,       --output-json       [false  ] output result in a JSON file\n",
            "  -of FNAME, --output-file FNAME [       ] output file path (without file extension)\n",
            "  -ps,       --print-special     [false  ] print special tokens\n",
            "  -pc,       --print-colors      [false  ] print colors\n",
            "  -pp,       --print-progress    [false  ] print progress\n",
            "  -nt,       --no-timestamps     [false  ] do not print timestamps\n",
            "  -l LANG,   --language LANG     [en     ] spoken language ('auto' for auto-detect)\n",
            "  -dl,       --detect-language   [false  ] exit after automatically detecting language\n",
            "             --prompt PROMPT     [       ] initial prompt\n",
            "  -m FNAME,  --model FNAME       [models/ggml-base.en.bin] model path\n",
            "  -f FNAME,  --file FNAME        [       ] input WAV file path\n",
            "  -oved D,   --ov-e-device DNAME [CPU    ] the OpenVINO device used for encode inference\n",
            "\n",
            "g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -pthread examples/bench/bench.cpp ggml.o whisper.o -o bench \n",
            "g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -pthread examples/quantize/quantize.cpp examples/common.cpp examples/common-ggml.cpp ggml.o whisper.o -o quantize \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run ggml-whisper on sample file"
      ],
      "metadata": {
        "id": "1DxBf3MWj8Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that main example currently runs only with 16-bit WAV files,\n",
        "# convert input before running the tool.'\n",
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/audio_3ai2\"\n",
        "i = 0\n",
        "print(path)\n",
        "# Loop through the files in the directory\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".mp3\"):  # Process only MP3 files\n",
        "        i += 1\n",
        "        print(file)\n",
        "\n",
        "        # Convert the MP3 to WAV using FFmpeg\n",
        "        input_file = os.path.join(path, file)\n",
        "        output_file = os.path.join(path, f\"wav_files/{i}.wav\")\n",
        "        !ffmpeg -i \"$input_file\" -ar 16000 -ac 1 -c:a pcm_s16le \"$output_file\"\n",
        "\n",
        "        # Process the WAV file using the \"main\" program\n",
        "        !./main -f \"$output_file\"\n",
        "\n"
      ],
      "metadata": {
        "id": "u7X746feDK2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Wd4vLLf86jOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redirect and save transcription output and transform to csv"
      ],
      "metadata": {
        "id": "8YPlXB9im24p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/audio_3ai2\"\n",
        "wav_folder = os.path.join(path, f\"wav_files\")\n",
        "i=0\n",
        "for wavf in wav_folder:\n",
        "  i=i+1\n",
        "  dest = os.path.join(path, f\"transcripts/{i}.txt\")\n",
        "  !./main -f wavf > dest\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkaGH8vbz9G0",
        "outputId": "e0912df3-587f-4446-81c7-45597c162a0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   184.11 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   282.79 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   176.45 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   272.56 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   166.19 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   262.56 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   169.17 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   264.57 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   167.78 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   262.36 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   163.93 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   259.50 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   164.82 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   259.40 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   164.20 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   259.00 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   165.09 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   260.63 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   204.68 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   325.38 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   208.61 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   327.85 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   228.56 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   347.62 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   202.18 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   318.46 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   229.56 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   366.63 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   214.41 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   333.70 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   232.90 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   351.38 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   230.76 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   351.26 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   217.79 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   343.06 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   184.88 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   282.02 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   166.78 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   260.76 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   163.69 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   260.93 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   182.43 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   277.68 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   165.95 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   260.01 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   166.71 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   260.83 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   174.82 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   269.02 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   162.82 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   257.21 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   168.20 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   261.34 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   177.70 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   275.84 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   162.40 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   258.93 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   166.27 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   263.15 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   175.49 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   271.38 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   167.80 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   261.93 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   168.20 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   266.93 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   172.54 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   268.31 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   163.16 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   256.06 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   168.56 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   269.71 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   167.66 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   262.87 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   169.79 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   263.94 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   171.13 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   267.43 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   173.97 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   268.23 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   170.51 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   275.52 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   164.34 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   259.38 ms\n",
            "whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'\n",
            "whisper_model_load: loading model\n",
            "whisper_model_load: n_vocab       = 51864\n",
            "whisper_model_load: n_audio_ctx   = 1500\n",
            "whisper_model_load: n_audio_state = 512\n",
            "whisper_model_load: n_audio_head  = 8\n",
            "whisper_model_load: n_audio_layer = 6\n",
            "whisper_model_load: n_text_ctx    = 448\n",
            "whisper_model_load: n_text_state  = 512\n",
            "whisper_model_load: n_text_head   = 8\n",
            "whisper_model_load: n_text_layer  = 6\n",
            "whisper_model_load: n_mels        = 80\n",
            "whisper_model_load: ftype         = 1\n",
            "whisper_model_load: qntvr         = 0\n",
            "whisper_model_load: type          = 2\n",
            "whisper_model_load: mem required  =  310.00 MB (+    6.00 MB per decoder)\n",
            "whisper_model_load: adding 1607 extra tokens\n",
            "whisper_model_load: model ctx     =  140.66 MB\n",
            "whisper_model_load: model size    =  140.54 MB\n",
            "whisper_init_state: kv self size  =    5.25 MB\n",
            "whisper_init_state: kv cross size =   17.58 MB\n",
            "error: failed to open 'wavf' as WAV file\n",
            "error: failed to read WAV file 'wavf'\n",
            "\n",
            "whisper_print_timings:     load time =   169.26 ms\n",
            "whisper_print_timings:     fallbacks =   0 p /   0 h\n",
            "whisper_print_timings:      mel time =     0.00 ms\n",
            "whisper_print_timings:   sample time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   encode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:   decode time =     0.00 ms /     1 runs (    0.00 ms per run)\n",
            "whisper_print_timings:    total time =   268.04 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !./main -f '/content/1.wav' > /content/transcription.txt"
      ],
      "metadata": {
        "id": "4FKf49jKnVS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def generate_transcription_csv(folder_path):\n",
        "    csv_file_path = os.path.join(folder_path, 'transcriptions.csv')\n",
        "\n",
        "    with open(csv_file_path, 'w') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['time_stamp', 'transcription', 'file_name'])  # Writing header\n",
        "\n",
        "        # Iterate through transcript files in the \"transcripts\" folder\n",
        "        transcript_folder = os.path.join(folder_path, 'transcripts')\n",
        "        for transcript_file in os.listdir(transcript_folder):\n",
        "            if transcript_file.endswith('.txt'):\n",
        "                transcript_path = os.path.join(transcript_folder, transcript_file)\n",
        "\n",
        "                # Extract the base name (without extension) of the transcript file\n",
        "                file_name = os.path.splitext(transcript_file)[0]\n",
        "\n",
        "                # Corresponding audio file path\n",
        "                audio_file_path = os.path.join(folder_path, 'wav_files', f'{file_name}.wav')\n",
        "\n",
        "                with open(transcript_path, 'r') as txt_file:\n",
        "                    for line in txt_file:\n",
        "                        line = line.strip()\n",
        "                        # Skip empty lines\n",
        "                        if line == '':\n",
        "                            continue\n",
        "\n",
        "                        # Split the line into timestamp and transcription\n",
        "                        time_stamp, transcription = line.split(']', 1)\n",
        "\n",
        "                        # Remove the leading '[' from the timestamp\n",
        "                        time_stamp = time_stamp[1:]\n",
        "\n",
        "                        # Remove leading and trailing spaces from the transcription\n",
        "                        transcription = transcription.strip()\n",
        "\n",
        "                        # Skip lines where the transcription is enclosed in square brackets\n",
        "                        if not (transcription.startswith('[') and transcription.endswith(']')):\n",
        "                            # Write the data to the CSV file\n",
        "                            csv_writer.writerow([time_stamp, transcription, file_name])\n",
        "\n",
        "    print(f\"CSV file has been saved at: {csv_file_path}\")\n",
        "\n",
        "\n",
        "# Replace 'audio_3ai2' with the actual folder path containing your data\n",
        "generate_transcription_csv('audio_3ai2')\n"
      ],
      "metadata": {
        "id": "tja__SBZ2_G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv\n",
        "\n",
        "# def generate_transcription_csv(text_file_path):\n",
        "#     csv_file_path = text_file_path.replace('.txt', '.csv')\n",
        "\n",
        "#     with open(text_file_path, 'r') as txt_file, open(csv_file_path, 'w') as csv_file:\n",
        "#         csv_writer = csv.writer(csv_file)\n",
        "#         csv_writer.writerow(['time_stamp', 'transcription'])  # Writing header\n",
        "\n",
        "#         for line in txt_file:\n",
        "#             line = line.strip()\n",
        "#             # Skip empty lines\n",
        "#             if line == '':\n",
        "#                 continue\n",
        "\n",
        "#             # Split the line into timestamp and transcription\n",
        "#             time_stamp, transcription = line.split(']', 1)\n",
        "\n",
        "#             # Remove the leading '[' from the timestamp\n",
        "#             time_stamp = time_stamp[1:]\n",
        "\n",
        "#             # Remove leading and trailing spaces from the transcription\n",
        "#             transcription = transcription.strip()\n",
        "\n",
        "#             # Skip lines where the transcription is enclosed in square brackets\n",
        "#             if not (transcription.startswith('[') and transcription.endswith(']')):\n",
        "#                 # Write the data to the CSV file\n",
        "#                 csv_writer.writerow([time_stamp, transcription])\n",
        "\n",
        "#     print(f\"CSV file has been saved at: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "THq-iVIGoyZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def generate_transcriptions_to_csv(folder_path):\n",
        "    transcript_folder = os.path.join(folder_path, 'transcripts')\n",
        "    csv_folder = os.path.join(folder_path, 'csv_output')\n",
        "\n",
        "    # Create the CSV folder if it doesn't exist\n",
        "    os.makedirs(csv_folder, exist_ok=True)\n",
        "\n",
        "    # Loop through transcript files in the \"transcripts\" folder\n",
        "    for transcript_file in os.listdir(transcript_folder):\n",
        "        if transcript_file.endswith('.txt'):\n",
        "            transcript_file_path = os.path.join(transcript_folder, transcript_file)\n",
        "            csv_file_path = os.path.join(csv_folder, transcript_file.replace('.txt', '.csv'))\n",
        "\n",
        "            with open(transcript_file_path, 'r') as txt_file, open(csv_file_path, 'w') as csv_file:\n",
        "                csv_writer = csv.writer(csv_file)\n",
        "                csv_writer.writerow(['time_stamp', 'transcription'])  # Writing header\n",
        "\n",
        "                for line in txt_file:\n",
        "                    line = line.strip()\n",
        "                    # ... (rest of the processing code)\n",
        "\n",
        "            print(f\"CSV file has been saved at: {csv_file_path}\")\n",
        "\n",
        "# Specify the path to the main folder containing transcripts\n",
        "main_folder_path = \"/content/audio_3ai2\"\n",
        "\n",
        "# Process transcripts and generate CSVs\n",
        "generate_transcriptions_to_csv(main_folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "mtalkxdb6CX9",
        "outputId": "fd69848f-9dfd-46f8-ecfc-2a9996b7f4ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9a8aa0cfff25>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Process transcripts and generate CSVs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mgenerate_transcriptions_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-9a8aa0cfff25>\u001b[0m in \u001b[0;36mgenerate_transcriptions_to_csv\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Loop through transcript files in the \"transcripts\" folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtranscript_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtranscript_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtranscript_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/audio_3ai2/transcripts'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_transcription_csv(\"/content/transcription.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHoruicGqHcH",
        "outputId": "5e1ab4b7-2c1e-4e8a-b58d-49d3077a396a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file has been saved at: /content/transcription.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modularize and put everything together"
      ],
      "metadata": {
        "id": "2UWMIgQ9vD3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/1.mp3 \"https://www.dropbox.com/s/9llt4ptcqvr77md/1.mp3?dl=0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSSKweHQ3C-A",
        "outputId": "bc4ebc60-f8c0-4c40-aceb-c86810743bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-04 20:11:47--  https://www.dropbox.com/s/9llt4ptcqvr77md/1.mp3?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/9llt4ptcqvr77md/1.mp3 [following]\n",
            "--2023-08-04 20:11:47--  https://www.dropbox.com/s/raw/9llt4ptcqvr77md/1.mp3\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb6a117dfe38066d6a4d6c45724.dl.dropboxusercontent.com/cd/0/inline/CBJj-7fAevwBNMAqWgVMpcFsRLibUMAwNvVVseh2qY3wkeC_YdnKR7hz2KAj9o55AehYAuW1Qk4IVqrSkD7iVvs8EeS6oLUH9_oDi-hK79ZQuXA01ZSRB8vRtQlyS_mfmlKZybWqqkE1Fa_c4oTvZ7I2/file# [following]\n",
            "--2023-08-04 20:11:48--  https://ucb6a117dfe38066d6a4d6c45724.dl.dropboxusercontent.com/cd/0/inline/CBJj-7fAevwBNMAqWgVMpcFsRLibUMAwNvVVseh2qY3wkeC_YdnKR7hz2KAj9o55AehYAuW1Qk4IVqrSkD7iVvs8EeS6oLUH9_oDi-hK79ZQuXA01ZSRB8vRtQlyS_mfmlKZybWqqkE1Fa_c4oTvZ7I2/file\n",
            "Resolving ucb6a117dfe38066d6a4d6c45724.dl.dropboxusercontent.com (ucb6a117dfe38066d6a4d6c45724.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to ucb6a117dfe38066d6a4d6c45724.dl.dropboxusercontent.com (ucb6a117dfe38066d6a4d6c45724.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6915017 (6.6M) [audio/mpeg]\n",
            "Saving to: ‘/content/1.mp3’\n",
            "\n",
            "/content/1.mp3      100%[===================>]   6.59M  10.8MB/s    in 0.6s    \n",
            "\n",
            "2023-08-04 20:11:49 (10.8 MB/s) - ‘/content/1.mp3’ saved [6915017/6915017]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/whisper.cpp.git\n",
        "\n",
        "%cd /content/whisper.cpp/models\n",
        "!bash download-ggml-model.sh base.en\n",
        "%cd ..\n",
        "!make\n",
        "\n",
        "!pip install pydub\n",
        "!apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhhnSa-lvDAt",
        "outputId": "eac55e4c-1eb3-40bf-a64e-ee4e3f30f646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'whisper.cpp' already exists and is not an empty directory.\n",
            "/content/whisper.cpp/models\n",
            "Downloading ggml model base.en from 'https://huggingface.co/ggerganov/whisper.cpp' ...\n",
            "Model base.en already exists. Skipping download.\n",
            "/content/whisper.cpp\n",
            "I whisper.cpp build info: \n",
            "I UNAME_S:  Linux\n",
            "I UNAME_P:  x86_64\n",
            "I UNAME_M:  x86_64\n",
            "I CFLAGS:   -I.              -O3 -DNDEBUG -std=c11   -fPIC -pthread -mavx2 -mfma -mf16c -mavx -msse3\n",
            "I CXXFLAGS: -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -pthread\n",
            "I LDFLAGS:  \n",
            "I CC:       cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:      g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "make: Nothing to be done for 'default'.\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import csv\n",
        "import subprocess\n",
        "\n",
        "def convert_to_wav(file_path):\n",
        "    # Split the file path into base and extension\n",
        "    base, ext = os.path.splitext(file_path)\n",
        "\n",
        "    # Only process files that aren't already in wav format\n",
        "    if ext.lower() != \".wav\":\n",
        "        # Load the audio file\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "\n",
        "        # Set frame rate to 16 kHz\n",
        "        audio = audio.set_frame_rate(16000)\n",
        "\n",
        "        # Save as wav\n",
        "        wav_file_path = base + \".wav\"\n",
        "        audio.export(wav_file_path, format=\"wav\")\n",
        "\n",
        "        print(f\"Saved as {wav_file_path}\")\n",
        "    else:\n",
        "        print(f\"File is already in wav format: {file_path}\")\n",
        "\n",
        "    return wav_file_path\n",
        "\n",
        "def transcript_wav_totext_using_whisper(wav_file_path):\n",
        "    base, ext = os.path.splitext(wav_file_path)\n",
        "    command = f\"./main -f '{wav_file_path}' >  {base}.txt\"\n",
        "    print(command)\n",
        "    process = subprocess.run(command, shell=True, check=True)\n",
        "\n",
        "    text_file_path = f'{base}.txt'\n",
        "\n",
        "    return text_file_path\n",
        "\n",
        "def generate_transcription_csv(text_file_path):\n",
        "    csv_file_path = text_file_path.replace('.txt', '.csv')\n",
        "\n",
        "    with open(text_file_path, 'r') as txt_file, open(csv_file_path, 'w') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['time_stamp', 'transcription'])  # Writing header\n",
        "\n",
        "        for line in txt_file:\n",
        "            line = line.strip()\n",
        "            # Skip empty lines\n",
        "            if line == '':\n",
        "                continue\n",
        "\n",
        "            # Split the line into timestamp and transcription\n",
        "            time_stamp, transcription = line.split(']', 1)\n",
        "\n",
        "            # Remove the leading '[' from the timestamp\n",
        "            time_stamp = time_stamp[1:]\n",
        "\n",
        "            # Remove leading and trailing spaces from the transcription\n",
        "            transcription = transcription.strip()\n",
        "\n",
        "            # Skip lines where the transcription is enclosed in square brackets\n",
        "            if not (transcription.startswith('[') and transcription.endswith(']')):\n",
        "                # Write the data to the CSV file\n",
        "                csv_writer.writerow([time_stamp, transcription])\n",
        "\n",
        "    print(f\"CSV file has been saved at: {csv_file_path}\")\n",
        "\n",
        "def process_folder(folder_path):\n",
        "    # Iterate through audio files in the \"wav_files\" folder\n",
        "    wav_folder = os.path.join(folder_path, 'wav_files')\n",
        "    for wav_file in os.listdir(wav_folder):\n",
        "        if wav_file.endswith('.wav'):\n",
        "            wav_file_path = os.path.join(wav_folder, wav_file)\n",
        "            text_file_path = transcript_wav_totext_using_whisper(wav_file_path)\n",
        "            generate_transcription_csv(text_file_path)\n",
        "\n",
        "\n",
        "# Specify the main folder path\n",
        "main_folder_path = \"audio_3ai2\"\n",
        "\n",
        "# Call the process_folder function to process all files in the folder\n",
        "process_folder(main_folder_path)\n"
      ],
      "metadata": {
        "id": "L-keiRiGvZDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# begin('/content/1.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K__ePbTvmFM",
        "outputId": "f6691ddb-b4ad-4999-9c09-6c66c49acc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved as /content/1.wav\n",
            "./main -f '/content/1.wav' >  /content/1.txt\n",
            "CSV file has been saved at: /content/1.csv\n",
            "DONE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add DOC_ID Column"
      ],
      "metadata": {
        "id": "mDm8qUGTi6Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def add_ids_to_csv_files(folder_path):\n",
        "    # Iterate through CSV files in the folder\n",
        "    csv_folder = os.path.join(folder_path, 'csv_files')\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            csv_file_path = os.path.join(csv_folder, csv_file)\n",
        "\n",
        "            # Read the CSV file\n",
        "            df = pd.read_csv(csv_file_path)\n",
        "\n",
        "            # Add the new column with values from 0 to n-1\n",
        "            df['DOC_ID'] = range(len(df))\n",
        "\n",
        "            # Save the updated DataFrame back to the CSV file\n",
        "            df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "            print(f\"Updated {csv_file_path} with IDs.\")\n",
        "\n",
        "\n",
        "# Specify the main folder path\n",
        "main_folder_path = \"audio_3ai2\"\n",
        "\n",
        "# Call the add_ids_to_csv_files function to process all CSV files in the folder\n",
        "add_ids_to_csv_files(main_folder_path)\n"
      ],
      "metadata": {
        "id": "q4WxTCCJMYMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Read the CSV file\n",
        "# df = pd.read_csv('/content/1.csv')\n",
        "\n",
        "# # Add the new column with values from 0 to n-1\n",
        "# df['DOC_ID'] = range(len(df))\n",
        "\n",
        "# # Save the updated DataFrame back to the CSV file\n",
        "# df.to_csv('/content/1.csv', index=False)"
      ],
      "metadata": {
        "id": "1MvSW8vSi5BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install thirdai --upgrade\n",
        "!pip3 install thirdai[neural_db]\n",
        "!pip3 install langchain --upgrade\n",
        "!pip3 install openai --upgrade\n",
        "!pip3 install paper-qa --upgrade"
      ],
      "metadata": {
        "id": "ZhlMc2bY_9oS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f559b1-537e-4b41-dc3f-9dca8c69f6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thirdai\n",
            "  Downloading thirdai-0.7.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from thirdai) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from thirdai) (4.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from thirdai) (2.27.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from thirdai) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->thirdai) (1.16.0)\n",
            "Installing collected packages: thirdai\n",
            "Successfully installed thirdai-0.7.16\n",
            "Requirement already satisfied: thirdai[neural_db] in /usr/local/lib/python3.10/dist-packages (0.7.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (4.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (2.27.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.5.3)\n",
            "Collecting PyTrie (from thirdai[neural_db])\n",
            "  Downloading PyTrie-0.4.0.tar.gz (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyMuPDF (from thirdai[neural_db])\n",
            "  Downloading PyMuPDF-1.22.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain (from thirdai[neural_db])\n",
            "  Downloading langchain-0.0.252-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bs4 (from thirdai[neural_db])\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trafilatura (from thirdai[neural_db])\n",
            "  Downloading trafilatura-1.6.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx (from thirdai[neural_db])\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting url-normalize (from thirdai[neural_db])\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (3.8.1)\n",
            "Collecting unidecode (from thirdai[neural_db])\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.10.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai[neural_db]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai[neural_db]) (2022.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->thirdai[neural_db]) (4.11.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain->thirdai[neural_db])\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain->thirdai[neural_db])\n",
            "  Downloading langsmith-0.0.18-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain->thirdai[neural_db])\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (8.2.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (4.65.0)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx->thirdai[neural_db]) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from PyTrie->thirdai[neural_db]) (2.4.0)\n",
            "Collecting courlan>=0.9.3 (from trafilatura->thirdai[neural_db])\n",
            "  Downloading courlan-0.9.3-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting htmldate>=1.4.3 (from trafilatura->thirdai[neural_db])\n",
            "  Downloading htmldate-1.4.3-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting justext>=3.0.0 (from trafilatura->thirdai[neural_db])\n",
            "  Downloading jusText-3.0.0-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of trafilatura to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting trafilatura (from thirdai[neural_db])\n",
            "  Downloading trafilatura-1.6.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.5.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.4.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.2.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from url-normalize->thirdai[neural_db]) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.3.1)\n",
            "Requirement already satisfied: langcodes>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=0.9.3->trafilatura->thirdai[neural_db]) (3.3.0)\n",
            "Collecting tld>=0.13 (from courlan>=0.9.3->trafilatura->thirdai[neural_db])\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db])\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting dateparser>=1.1.2 (from htmldate>=1.4.3->trafilatura->thirdai[neural_db])\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of htmldate to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting htmldate>=1.2.1 (from trafilatura->thirdai[neural_db])\n",
            "  Downloading htmldate-1.4.2-py3-none-any.whl (33 kB)\n",
            "  Downloading htmldate-1.4.1-py3-none-any.whl (33 kB)\n",
            "  Downloading htmldate-1.4.0-py3-none-any.whl (33 kB)\n",
            "  Downloading htmldate-1.3.2-py3-none-any.whl (39 kB)\n",
            "  Downloading htmldate-1.3.1-py3-none-any.whl (39 kB)\n",
            "  Downloading htmldate-1.3.0-py3-none-any.whl (32 kB)\n",
            "  Downloading htmldate-1.2.3-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->thirdai[neural_db]) (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->thirdai[neural_db]) (2.4.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.4.3->trafilatura->thirdai[neural_db]) (5.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: bs4, python-docx, PyTrie\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=36e71173b174c364c656b30ce48d3171d0b7c17b46bfe95c94dcbd54a80e9d42\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184489 sha256=608cd9d61ccd6d99a67bc79c9bd8e446feecbd775139bf76b55a907abf38b0e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for PyTrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTrie: filename=PyTrie-0.4.0-py3-none-any.whl size=6080 sha256=d87e26ca51bad70286d2f25d76aebcda7cd083c33a29480a1f959992807ab0ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/0e/a3/3563272cb57af4afbc50c4c7882dd4540944aadde25c82bd45\n",
            "Successfully built bs4 python-docx PyTrie\n",
            "Installing collected packages: url-normalize, unidecode, tld, PyTrie, python-docx, PyMuPDF, mypy-extensions, marshmallow, justext, typing-inspect, openapi-schema-pydantic, langsmith, dateparser, courlan, bs4, htmldate, dataclasses-json, trafilatura, langchain\n",
            "Successfully installed PyMuPDF-1.22.5 PyTrie-0.4.0 bs4-0.0.1 courlan-0.9.3 dataclasses-json-0.5.14 dateparser-1.1.8 htmldate-1.2.3 justext-3.0.0 langchain-0.0.252 langsmith-0.0.18 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 python-docx-0.8.11 tld-0.13 trafilatura-1.2.2 typing-inspect-0.9.0 unidecode-1.3.6 url-normalize-1.4.3\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.252)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.18)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting paper-qa\n",
            "  Downloading paper_qa-3.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting pypdf (from paper-qa)\n",
            "  Downloading pypdf-3.14.0-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain>=0.0.198 in /usr/local/lib/python3.10/dist-packages (from paper-qa) (0.0.252)\n",
            "Requirement already satisfied: openai>=0.27.8 in /usr/local/lib/python3.10/dist-packages (from paper-qa) (0.27.8)\n",
            "Collecting faiss-cpu (from paper-qa)\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyCryptodome (from paper-qa)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2text (from paper-qa)\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Collecting tiktoken>=0.4.0 (from paper-qa)\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (0.0.18)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.8->paper-qa) (4.65.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->paper-qa) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain>=0.0.198->paper-qa) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.198->paper-qa) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (1.0.0)\n",
            "Installing collected packages: faiss-cpu, pypdf, PyCryptodome, html2text, tiktoken, paper-qa\n",
            "Successfully installed PyCryptodome-3.18.0 faiss-cpu-1.7.4 html2text-2020.1.16 paper-qa-3.5.0 pypdf-3.14.0 tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from thirdai import licensing, neural_db as ndb\n",
        "licensing.deactivate()\n",
        "licensing.activate(\"1FB7DD-CAC3EC-832A67-84208D-C4E39E-V3\")"
      ],
      "metadata": {
        "id": "LP1Np_5tEBay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = ndb.NeuralDB(user_id=\"root\")"
      ],
      "metadata": {
        "id": "5C4CrYQXFC1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pandas_gbq import ndb\n",
        "\n",
        "def process_csv_files(folder_path):\n",
        "    insertable_docs = []\n",
        "\n",
        "    # Iterate through CSV files in the folder\n",
        "    csv_folder = os.path.join(folder_path, 'csv_files')\n",
        "    for csv_file in os.listdir(csv_folder):\n",
        "        if csv_file.endswith('.csv'):\n",
        "            csv_file_path = os.path.join(csv_folder, csv_file)\n",
        "\n",
        "            # Read the CSV file\n",
        "            df = pd.read_csv(csv_file_path)\n",
        "\n",
        "            # Create a CSV document\n",
        "            csv_doc = ndb.CSV(\n",
        "                path=csv_file_path,\n",
        "                id_column=\"DOC_ID\",\n",
        "                strong_columns=[\"transcription\"],\n",
        "                weak_columns=[\"time_stamp\"],\n",
        "                reference_columns=[\"time_stamp\"])\n",
        "\n",
        "            insertable_docs.append(csv_doc)\n",
        "\n",
        "    return insertable_docs\n",
        "\n",
        "\n",
        "# Specify the main folder path\n",
        "main_folder_path = \"audio_3ai2\"\n",
        "\n",
        "# Call the process_csv_files function to process all CSV files in the folder\n",
        "insertable_docs = process_csv_files(main_folder_path)\n",
        "\n",
        "# Now you can use the insertable_docs list for further processing\n"
      ],
      "metadata": {
        "id": "cOtjQTGXNQN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insertable_docs = []\n",
        "# csv_files = ['/content/1.csv']\n",
        "\n",
        "# for file in csv_files:\n",
        "#     csv_doc = ndb.CSV(\n",
        "#         path=file,\n",
        "#         id_column=\"DOC_ID\",\n",
        "#         strong_columns=[\"transcription\"],\n",
        "#         weak_columns=[\"time_stamp\"],\n",
        "#         reference_columns=[\"time_stamp\"])\n",
        "#     #\n",
        "#     insertable_docs.append(csv_doc)"
      ],
      "metadata": {
        "id": "edt4Y8uHFREm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_ids = db.insert(insertable_docs, train=True)"
      ],
      "metadata": {
        "id": "VuL_CHCkOvEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source_ids = db.insert(insertable_docs, train=True)"
      ],
      "metadata": {
        "id": "DGqrG5RYrmF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b6eea3-9f3f-4ca7-8574-a9f33cd3afe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded data | source 'Documents:\n",
            "1.csv' | vectors 278 | batches 1 | time 0s | complete\n",
            "\n",
            "train | epoch 0 | train_steps 1 | train_hash_precision@5=0.018705  | train_batches 1 | time 3s\n",
            "\n",
            "train | epoch 1 | train_steps 2 | train_hash_precision@5=0.551799  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 2 | train_steps 3 | train_hash_precision@5=0.361151  | train_batches 1 | time 1s\n",
            "\n",
            "train | epoch 3 | train_steps 4 | train_hash_precision@5=0.295683  | train_batches 1 | time 1s\n",
            "\n",
            "train | epoch 4 | train_steps 5 | train_hash_precision@5=0.328058  | train_batches 1 | time 1s\n",
            "\n",
            "train | epoch 5 | train_steps 6 | train_hash_precision@5=0.397122  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 6 | train_steps 7 | train_hash_precision@5=0.523741  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 7 | train_steps 8 | train_hash_precision@5=0.666906  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 8 | train_steps 9 | train_hash_precision@5=0.802878  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 9 | train_steps 10 | train_hash_precision@5=0.883453  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 10 | train_steps 11 | train_hash_precision@5=0.921583  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 11 | train_steps 12 | train_hash_precision@5=0.941007  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 12 | train_steps 13 | train_hash_precision@5=0.938129  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 13 | train_steps 14 | train_hash_precision@5=0.959712  | train_batches 1 | time 0s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = db.search(\n",
        "    query=\"what is Starkel average for January is 31 degrees\",\n",
        "    top_k=2,\n",
        "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
        "\n",
        "for result in search_results:\n",
        "    print(result.text)\n",
        "    print(result.context(radius=1))\n",
        "    print(result.source)\n",
        "    print(result.metadata)\n",
        "    print('************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0L1bb92OEtY",
        "outputId": "1474aaf0-b1d1-4419-fcde-47d227dc7834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00:06:26.000 --> 00:06:33.000\n",
            "/content/1.csv\n",
            "{'time_stamp': '00:06:26.000 --> 00:06:33.000', 'transcription': \"Starkel average for January's is 31 degrees, last month was 39.5 degrees.\", 'DOC_ID': 58}\n",
            "************\n",
            "00:06:17.000 --> 00:06:26.000\n",
            "/content/1.csv\n",
            "{'time_stamp': '00:06:17.000 --> 00:06:26.000', 'transcription': 'Just in the last two days, we got the new temperature records in January. This is just for the United States of America.', 'DOC_ID': 57}\n",
            "************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBsvOPe_OZpX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}